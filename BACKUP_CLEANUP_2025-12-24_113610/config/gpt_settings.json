{
  "_metadata": {
    "description": "GPT Configuration for Candidate Insights Generation",
    "last_updated": "2025-12-18 05:33:59 UTC",
    "warning": "Changes to these settings affect both quality and cost. Test with small batches first."
  },
  "gpt_model": {
    "value": "gpt-4o",
    "description": "OpenAI model to use for generating candidate insights",
    "options": [
      "gpt-4o",
      "gpt-4o-mini",
      "gpt-4-turbo",
      "gpt-4"
    ],
    "explanation": "gpt-4o: Best balance of quality and cost (RECOMMENDED). gpt-4o-mini: 60% cheaper but lower quality. gpt-4-turbo: Same cost as gpt-4o, slightly different outputs. gpt-4: More expensive, no benefit for this task.",
    "cost_impact": "gpt-4o: $2.50 per 1M input tokens, $10 per 1M output. gpt-4o-mini: $0.15/$0.60. gpt-4-turbo: $10/$30. gpt-4: $30/$60.",
    "quality_impact": "gpt-4o provides personalized, specific insights. gpt-4o-mini may be more generic. gpt-4/turbo offer no quality advantage here."
  },
  "temperature": {
    "value": 0.2,
    "description": "Controls randomness in GPT responses (0.0 = deterministic, 2.0 = very creative)",
    "range": [
      0.0,
      2.0
    ],
    "explanation": "Lower values (0.0-0.3) produce consistent, focused insights. Higher values (0.7-1.0) produce more varied, creative responses. For professional hiring insights, keep LOW.",
    "recommended": 0.2,
    "cost_impact": "No cost impact - only affects output style",
    "quality_impact": "0.2 ensures consistent, professional insights. Higher temps may introduce unnecessary creativity or inconsistency."
  },
  "max_tokens": {
    "value": 1000,
    "description": "Maximum number of tokens (words) in GPT response",
    "range": [
      500,
      2000
    ],
    "explanation": "Current insights need ~400-600 tokens (3-6 bullets for strengths, 3-6 for gaps, 2-4 sentence notes). 1000 provides safety margin without waste.",
    "recommended": 1000,
    "cost_impact": "Linear cost increase. 1000 tokens = ~$0.01 per insight with gpt-4o. 2000 tokens = ~$0.02. We typically only use ~500.",
    "quality_impact": "Too low (<500) may truncate insights. Too high (>1500) wastes money with no benefit."
  },
  "evidence_snippet_chars": {
    "value": 600,
    "description": "Characters per criterion in evidence snippets sent to GPT",
    "range": [
      200,
      1000
    ],
    "explanation": "Each criterion gets a snippet of resume text showing why the candidate scored well/poorly. More chars = better context but higher cost.",
    "recommended": 600,
    "cost_impact": "With 20 criteria: 400 chars = ~4000 input tokens. 600 chars = ~5000 tokens (+$0.002 per insight). 1000 chars = ~8000 tokens (+$0.010).",
    "quality_impact": "400 chars: Often cuts mid-sentence. 600 chars: Good context, complete thoughts. 1000 chars: Diminishing returns - GPT gets enough from 600."
  },
  "candidate_text_chars": {
    "value": 3000,
    "description": "Characters of candidate resume text sent to GPT for context",
    "range": [
      1000,
      10000
    ],
    "explanation": "Full resume is sent (truncated to this limit) to give GPT overall context about candidate. First 3000 chars usually captures name, summary, recent experience.",
    "recommended": 3000,
    "cost_impact": "3000 chars = ~750 tokens. 5000 chars = ~1250 tokens (+$0.001). 10000 chars = ~2500 tokens (+$0.004).",
    "quality_impact": "3000 chars captures critical info (header, summary, recent roles). More doesn't significantly improve insights since evidence snippets provide specifics."
  },
  "jd_text_chars": {
    "value": 3000,
    "description": "Characters of Job Description sent to GPT for context",
    "range": [
      1000,
      10000
    ],
    "explanation": "Job description is sent (truncated) so GPT understands what role we're hiring for. First 3000 chars captures overview and key requirements.",
    "recommended": 3000,
    "cost_impact": "Same as candidate_text_chars - 3000 = ~750 tokens. Linear increase with length.",
    "quality_impact": "3000 chars sufficient for most JDs. Longer JDs don't improve insights much since criteria are explicitly scored."
  },
  "score_thresholds": {
    "high_threshold": {
      "value": 0.75,
      "description": "Score above this = 'High' or 'Strong' match (green in UI)",
      "range": [
        0.6,
        0.9
      ],
      "explanation": "Criteria with scores \u00e2\u2030\u00a50.75 are considered strong matches. Lower threshold = more criteria marked 'strong'. Higher = more selective.",
      "recommended": 0.75,
      "quality_impact": "Affects UI color coding and what GPT considers a 'strength'. Too low dilutes meaning of 'strong'."
    },
    "low_threshold": {
      "value": 0.35,
      "description": "Score below this = 'Low' or 'Weak' match (red in UI)",
      "range": [
        0.2,
        0.5
      ],
      "explanation": "Criteria with scores <0.35 are considered weak/gaps. Lower threshold = fewer marked as gaps. Higher = more gaps shown.",
      "recommended": 0.35,
      "quality_impact": "Affects UI color coding and what GPT considers a 'gap'. Too high creates false negatives."
    }
  },
  "pricing_config": {
    "base_price_usd": {
      "value": 4.0,
      "description": "Base price for analysis (JD extraction + scoring all candidates + top 3 insights)",
      "explanation": "This covers OpenAI costs for JD extraction (~$0.05) + semantic scoring (~$0.01 per candidate) + 3 insights (~$0.054). Rest is profit margin."
    },
    "extra_insight_price_usd": {
      "value": 1.0,
      "description": "Price per additional insight beyond top 3",
      "explanation": "Each extra insight costs ~$0.018 in OpenAI fees. $1.00 provides 98% profit margin while staying affordable."
    },
    "model_costs": {
      "gpt-4o": {
        "input_per_million": 2.5,
        "output_per_million": 10.0
      },
      "gpt-4o-mini": {
        "input_per_million": 0.15,
        "output_per_million": 0.6
      },
      "gpt-4-turbo": {
        "input_per_million": 10.0,
        "output_per_million": 30.0
      },
      "gpt-4": {
        "input_per_million": 30.0,
        "output_per_million": 60.0
      }
    }
  },
  "advanced_settings": {
    "prompt_style": {
      "value": "concise_professional",
      "description": "Style of insights generated",
      "options": [
        "concise_professional",
        "detailed_analytical",
        "bullet_points_only"
      ],
      "explanation": "concise_professional: 3-6 bullets + paragraph (CURRENT). detailed_analytical: Longer, more verbose. bullet_points_only: Skip the notes paragraph.",
      "note": "Changing this requires modifying the prompt template in analysis.py - not yet implemented in admin UI."
    },
    "include_candidate_name_in_prompt": {
      "value": true,
      "description": "Whether to include candidate name in GPT prompt",
      "explanation": "Including the name helps GPT personalize insights ('Nigel has...' vs 'The candidate has...'). Recommended: true.",
      "quality_impact": "Significantly improves personalization and readability of insights."
    },
    "top_evidence_items": {
      "value": 10,
      "description": "Number of criteria evidence snippets to include (sorted by score)",
      "range": [
        5,
        20
      ],
      "explanation": "We send top N criteria by score to GPT. More = better context but higher cost. 10 balances both.",
      "recommended": 10,
      "cost_impact": "Directly multiplies evidence_snippet_chars cost. 10 items \u00c3\u2014 600 chars = 6000 chars. 20 items = 12000 chars (double cost)."
    }
  },
  "_usage_notes": {
    "current_cost_per_insight": "~$0.018 with current settings (gpt-4o, 600 char evidence, 3000 char context)",
    "recommended_workflow": "1. Test changes with 'Top 3' insights first. 2. Check quality in Insights page. 3. Monitor costs in analysis history. 4. Adjust gradually.",
    "optimization_priority": "1. Keep model=gpt-4o (best quality/cost). 2. Adjust evidence_snippet_chars if quality issues (600-800 range). 3. Keep temperature low (0.1-0.3). 4. Don't touch candidate/jd text limits unless necessary.",
    "cost_saving_tips": "Switch to gpt-4o-mini for 60% cost reduction (test quality first). Reduce evidence snippets to 400-500 chars. Lower top_evidence_items to 8.",
    "quality_improvement_tips": "Increase evidence_snippet_chars to 800. Include more evidence items (15-20). Keep temperature at 0.2. Ensure candidate_text includes full resume header."
  }
}