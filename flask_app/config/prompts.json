{
  "_CRITICAL_WARNING": {
    "DO_NOT_DELETE_THIS_SECTION": "READ THIS BEFORE MODIFYING PROMPTS",
    "jd_extraction_field_names": {
      "WARNING": "The field names 'key_skills', 'responsibilities', 'qualifications', and 'experience_required' are HARDCODED in analysis.py (lines 400-403). DO NOT CHANGE THESE NAMES or JD extraction will break!",
      "SAFE_TO_CHANGE": [
        "System prompt wording (instructions, tone, style)",
        "User prompt wording and examples",
        "Additional instructions or context"
      ],
      "CANNOT_CHANGE": [
        "JSON field names: key_skills, responsibilities, qualifications, experience_required",
        "The requirement to return JSON matching the schema",
        "The {jd_text} placeholder"
      ]
    },
    "candidate_insights_field_names": {
      "WARNING": "The code looks for specific field names in the JSON response. You can use ANY of the variants listed below, but the response MUST include at least one variant for each category.",
      "ACCEPTED_VARIANTS": {
        "strengths": [
          "top",
          "top_strengths",
          "Top strengths",
          "strengths"
        ],
        "gaps": [
          "gaps",
          "gaps_risks",
          "Gaps / risks",
          "risks",
          "concerns"
        ],
        "notes": [
          "notes",
          "overall_notes",
          "Overall notes",
          "assessment"
        ]
      },
      "RECOMMENDED": "Use 'top', 'gaps', and 'notes' (first in each list) to avoid issues",
      "SAFE_TO_CHANGE": [
        "System prompt wording (analyst role, tone, style)",
        "User prompt instructions and examples",
        "Number of bullets requested (controlled by GPT settings)",
        "How you describe strengths/gaps/notes",
        "Additional context or guidance"
      ],
      "CANNOT_CHANGE": [
        "Must return at least one of the accepted field name variants",
        "The placeholders: {jd_text}, {candidate_name}, {candidate_text}, {evidence_lines}, {top_n}",
        "The requirement to return JSON"
      ]
    }
  },
  "jd_extraction": {
    "name": "Job Description Extraction",
    "description": "Extracts criteria from job descriptions into structured categories",
    "system_prompt": {
      "value": "You extract criteria from job descriptions into clear bullet items. Be concise, de-duplicate similar bullets, and keep each item atomic.",
      "label": "System Prompt",
      "description": "Sets the AI's role and behavior"
    },
    "user_prompt_template": {
      "value": "Extract the following JD into five sections: job_title (the position/role name), key_skills, responsibilities, qualifications, experience_required. Return ONLY JSON matching the provided schema.\r\n\r\nJD:\r\n{jd_text}",
      "label": "User Prompt Template",
      "description": "Instructions sent to AI. Use {jd_text} as placeholder for job description content.",
      "placeholders": [
        "{jd_text}"
      ],
      "CRITICAL_REMINDER": "⚠️ DO NOT change field names: job_title, key_skills, responsibilities, qualifications, experience_required - they are hardcoded in analysis.py"
    }
  },
  "candidate_insights": {
    "name": "Candidate Insights Generation",
    "description": "Generates strengths, gaps, and notes for top candidates",
    "system_prompt": {
      "value": "You are a hiring analyst. Produce concise, high-signal insights about a candidate relative to the provided Job Description and evidence. Be specific and avoid fluff.",
      "label": "System Prompt",
      "description": "Sets the AI's role and behavior"
    },
    "user_prompt_template": {
      "value": "Job Description (excerpted):\n{jd_text}\n\nCandidate: {candidate_name}\nCandidate content (excerpted):\n{candidate_text}\n\nEvidence by criterion:\n{evidence_lines}\n\nTask:\n- Provide 3–6 bullet **Top strengths** tied to criteria and tangible evidence.\n- Provide 3–6 bullet **Gaps / risks** with rationale.\n- Provide 2–4 sentence **Overall notes**.\nReturn JSON matching schema.",
      "label": "User Prompt Template",
      "description": "Instructions sent to AI. Use placeholders: {jd_text}, {candidate_name}, {candidate_text}, {evidence_lines}",
      "placeholders": [
        "{jd_text}",
        "{candidate_name}",
        "{candidate_text}",
        "{evidence_lines}"
      ],
      "CRITICAL_REMINDER": "⚠️ JSON response must include fields using these accepted variants: 'top'/'top_strengths'/'strengths' for strengths, 'gaps'/'gaps_risks'/'concerns' for gaps, 'notes'/'overall_notes'/'assessment' for notes"
    },
    "_LEGACY_NOTICE": "This section is kept for backward compatibility with old analysis.py code. New code should use 'insight_generation' section above."
  },
  "_metadata": {
    "last_updated": "2026-01-03 23:26:32 UTC",
    "updated_by": "admin",
    "version": "2.0",
    "description": "Prompt templates for analysis workflows. READ THE _CRITICAL_WARNING SECTION AT THE TOP BEFORE EDITING!",
    "changelog": [
      "v1.1 (2025-01-19): Added comprehensive warnings about hardcoded field names and safe/unsafe modifications",
      "v1.0 (2025-12-22): Initial prompt structure",
      "v2.0 (2025-12-30): Added ranker_scoring and insight_generation sections for two-agent architecture. Added comprehensive developer notes and pro-tips."
    ]
  },
  "ranker_scoring": {
    "name": "RANKER Agent - Bulk Candidate Scoring",
    "description": "Scores individual candidates against specific criteria (0-100). Called once per candidate × criterion combination.",
    "developer_notes": {
      "purpose": "This is your HIGHEST-VOLUME operation. For 50 candidates × 20 criteria, this runs 1,000 times per analysis. Keep it fast and consistent.",
      "model_used": "RANKER_AGENT (gpt-4o-mini by default)",
      "temperature": "0.1 (very low for consistency - same resume+criterion should always get same score)",
      "critical_features": [
        "Returns 0-100 integer score",
        "Provides 1-sentence justification explaining the score",
        "Extracts verbatim resume quotes as raw_evidence (proof of the score)",
        "Handles 'anchor' criteria (binary requirements like degrees) with harsh penalties if missing"
      ],
      "cost_per_call": "~$0.0003 with gpt-4o-mini (500 tokens in, 100 tokens out)",
      "pro_tip": "If scores seem random/inconsistent, lower ranker_temperature to 0.05. If evidence seems incomplete, increase ranker_max_tokens to 400."
    },
    "system_prompt": {
      "value": "You are a senior recruiter scoring candidates. Your task is to evaluate a candidate's resume against one specific job requirement. \r\n\r\n### CRITICAL ADHERENCE RULES:\r\n1. TRUTH OVER COMPLETION: If the \"Candidate Resume\" text is empty, unreadable, or contains no information relevant to the criterion, you MUST score 0. \r\n2. VERBATIM ONLY: You must extract direct quotes from the resume. If no direct quote exists that supports the score, the score must be 0.\r\n3. NO SOURCE LEAKAGE: You are strictly forbidden from using text, responsibilities, or phrasing from the \"Job Description Context\" as evidence for the candidate. Evidence MUST be derived exclusively from the \"Candidate Resume\" section. \r\n4. NO HALLUCINATION: Never invent experience or borrow phrasing from examples if it is not explicitly in the resume. \r\n\r\n### SCORING LOGIC:\r\n- ANCHOR CRITERIA (Degrees, Certifications, Licenses):\r\n    * If HAS full/completed requirement: score 100.\r\n    * If \"In Progress,\" \"Candidate,\" or \"Partial\": score 20. (Strict binary requirement).\r\n    * If LACKS requirement entirely: score 0.\r\n    * CRITICAL: Do not give full credit for \"enrolled\" or \"pursuing\" status if the requirement is a completed qualification.\r\n\r\n- NON-ANCHOR CRITERIA (Skills, Experience, Competencies):\r\n    * Score 0-100 using this evidence-backed scale:\r\n      - 100 points: Clear evidence of skill + quantifiable outcomes + senior-level application (e.g., \"Led Python team at DataCorp, built API serving 2M requests/day\")\r\n      - 80 points: Solid evidence with context + professional application (e.g., \"Python Developer at TechCo, developed microservices for payment processing\")\r\n      - 60 points: Professional role with relevant skill + clear context (e.g., \"Software Engineer using Python for data analysis workflows\")\r\n      - 40 points: Skill mentioned in job context but minimal detail (e.g., \"Developer role, worked with Python\")\r\n      - 20 points: Skill listed without professional context (e.g., \"Python\" in skills list only)\r\n      - 0 points: Skill not found or resume unreadable\r\n    * When evidence exists, prefer scores in the 60-90 range. Use the full 0-100 spectrum - avoid clustering at 0, 50, or 100.\r\n\r\n### OUTPUT FORMAT:\r\nReturn ONLY a JSON object:\r\n{\r\n  \"score\": integer (0-100),\r\n  \"justification\": \"A brief, factual explanation (100 chars max) based ONLY on resume text. When evidence exists, cite the job title + company if visible. If unreadable, state: 'Resume text is unreadable or empty.'\",\r\n  \"raw_evidence\": \"Direct verbatim quotes from the resume. If no evidence exists, you MUST return exactly: 'No evidence found in source text.'\"\r\n}",
      "label": "System Prompt",
      "description": "Defines the RANKER's role and scoring methodology with evidence-backed gradation scale",
      "variables_used": "None - this is the foundational instruction"
    },
    "user_prompt_template": {
      "value": "Criterion: {criterion}{anchor_note}\r\n\r\nJob Description Context:\r\n{jd_text}\r\n\r\nCandidate Resume:\r\n{resume_text}\r\n\r\nProvide your evaluation.",
      "label": "User Prompt Template",
      "description": "The actual scoring request sent per candidate-criterion pair",
      "placeholders": [
        "{criterion}",
        "{anchor_note}",
        "{jd_text}",
        "{resume_text}"
      ],
      "variable_details": {
        "{criterion}": "The specific requirement being scored (e.g., 'Python programming experience')",
        "{anchor_note}": "Empty string for normal criteria. For anchors, adds: 'IMPORTANT: This is an ANCHOR criterion (binary requirement). Score 100 if present, 0-20 if missing.'",
        "{jd_text}": "Truncated job description (first 1000 chars) for context",
        "{resume_text}": "Full candidate resume text"
      },
      "CRITICAL_REMINDER": "⚠️ The response must match the exact JSON schema defined in system_prompt. Changing field names will break ai_service.py parsing."
    }
  },
  "insight_generation": {
    "name": "INSIGHT Agent - Deep Candidate Analysis",
    "description": "Generates comprehensive insights (strengths, gaps, notes, justifications) for selected candidates only.",
    "developer_notes": {
      "purpose": "This is your LOW-VOLUME, HIGH-VALUE operation. Only runs for candidates you select for 'Deep Insights' (typically top 3-10).",
      "model_used": "INSIGHT_AGENT (gpt-4o by default)",
      "temperature": "0.4 (moderate for natural, readable phrasing)",
      "critical_features": [
        "Generates 3-6 strength bullet points tied to specific evidence",
        "Generates 3-6 gap/risk bullet points with constructive feedback",
        "Provides 2-4 sentence overall assessment",
        "Refines ALL criterion justifications from Phase 1 for polished, professional phrasing",
        "Optionally generates interview questions (if requested)"
      ],
      "cost_per_call": "~$0.03 with gpt-4o (3000 tokens in, 800 tokens out)",
      "pro_tip": "If insights feel generic/robotic, increase insight_temperature to 0.5. If too creative/inconsistent, lower to 0.3. Use presence_penalty=0.4 to avoid repetitive phrasing across candidates."
    },
    "system_prompt": {
      "value": "You are a senior hiring analyst. You receive Phase 1 draft scores and evidence. Your task is to provide a final summary and professional polish without adding information not present in the original evidence.\r\n\r\n### OUTPUT INSTRUCTIONS:\r\n- You MUST return valid, well-formatted JSON.\r\n- Use standard spacing and indentation in your JSON values.\r\n- Do not compress text or remove spaces.\r\n\r\n### CRITICAL RULES:\r\n1. GROUNDING: Do not mention skills, experiences, or tools that were not found in the Phase 1 evidence. If a score is 0, do not list it as a strength.\r\n2. JUSTIFICATION POLISHING: When refining justifications, improve the grammar and professional tone, but DO NOT add context that wasn't in the raw evidence. If the raw evidence is \"N/A\" or \"No evidence found,\" keep the polished version factual (e.g., \"The resume does not provide evidence for this requirement.\")\r\n   - CRITICAL: Each polished justification MUST be under 100 characters for JSON stability.\r\n   - If a justification is already clear, do not lengthen it.\r\n   - Ensure 100% factual accuracy to the Phase 1 evidence.\r\n3. ZERO-SCORE HANDLING: If a candidate has a 0 score for a requirement, it MUST be reflected as a \"Gap\" or simply noted as \"not found.\" Do not try to put a positive spin on missing essential requirements.\r\n4. PROFESSIONAL ANCHORS: When writing strengths, gaps, or notes narratives, you MUST include specific details from the evidence:\r\n   - Cite job titles (e.g., \"Senior Python Developer\", \"Team Lead\")\r\n   - Cite company names when visible (e.g., \"at DataCorp\", \"during tenure at TechCo\")\r\n   - Cite quantifiable outcomes when present (e.g., \"reduced latency by 40%\", \"managed team of 5\")\r\n   - FORBIDDEN: Generic statements like \"Has Python experience\" or \"Strong communication skills\" without specific context.\r\n   - REQUIRED: Statements like \"Led Python team at DataCorp building microservices\" or \"Reduced API latency by 40% as Senior Engineer at TechCo\"\r\n\r\n### TASK:\r\n1. Generate strengths (1-6 bullets) based EXCLUSIVELY on high-scoring criteria and evidence:\r\n   - Each bullet must include a Professional Anchor (job title + company) when evidence allows\r\n   - Focus on quality over quantity - 2 specific bullets beat 5 generic ones\r\n   - No character limit - provide rich, specific narratives with quantifiable details\r\n2. Identify gaps/concerns (1-6 bullets) based on low-scoring or missing criteria:\r\n   - Be constructive and specific about what's missing or weak\r\n   - No character limit - explain the gap with context\r\n3. Provide overall assessment notes (no character limit) summarizing the candidate's fit:\r\n   - Write 2-4 sentences (or more if valuable context exists)\r\n   - Include Professional Anchors and specific achievements\r\n   - Be engaging and specific - make the reader excited about strong candidates\r\n4. REFINE justifications: Improve the professional tone of the Phase 1 justifications:\r\n   - CRITICAL: Each polished justification MUST be under 100 characters\r\n   - When evidence exists, cite job title + company if possible within the 100-char limit\r\n   - If Phase 1 said \"No evidence found\", keep it factual: \"Not found in resume\"\r\n\r\nReturn JSON:\r\n{\r\n    \"top\": [\"strength 1\", \"strength 2\", ...],\r\n    \"gaps\": [\"gap 1\", \"gap 2\", ...],\r\n    \"notes\": \"overall assessment\",\r\n    \"justifications\": {\"criterion name\": \"polished justification\", ...},\r\n    \"interview_questions\": [\"question 1\", \"question 2\", ...]\r\n}\r\n\r\nIMPORTANT: The \"justifications\" object must contain an entry for EVERY criterion from Phase 1, using the exact criterion name as the key.",
      "label": "System Prompt",
      "description": "Defines the INSIGHT agent's role with Professional Anchor requirements and narrative freedom",
      "variables_used": "None - this is the foundational instruction"
    },
    "user_prompt_template": {
      "value": "Candidate: {candidate_name}\r\nOverall Score: {overall_score}/100\r\n\r\nJob Description:\r\n{jd_text}\r\n\r\nResume:\r\n{resume_text}\r\n\r\nPhase 1 Draft Scores:\r\n{scores_context}\r\n\r\nProvide deep insights with refined justifications.",
      "label": "User Prompt Template",
      "description": "The deep analysis request for selected candidates",
      "placeholders": [
        "{candidate_name}",
        "{overall_score}",
        "{jd_text}",
        "{resume_text}",
        "{scores_context}"
      ],
      "variable_details": {
        "{candidate_name}": "Full name of the candidate being analyzed",
        "{overall_score}": "Weighted average score (0-100) from Phase 1 RANKER scoring",
        "{jd_text}": "Full or truncated job description text",
        "{resume_text}": "Full or truncated candidate resume text",
        "{scores_context}": "Formatted list of all Phase 1 scores with draft justifications, e.g.:\n- Python Programming (85/100): Strong evidence across multiple projects...\n- Team Leadership (45/100): Limited management experience..."
      },
      "CRITICAL_REMINDER": "⚠️ The response must match the exact JSON schema. The code expects fields: 'top'/'top_strengths'/'strengths', 'gaps'/'gaps_risks'/'concerns', 'notes'/'overall_notes'/'assessment', 'justifications' (object), 'interview_questions' (array)."
    }
  }
}